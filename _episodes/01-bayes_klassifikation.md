---
# Please do not edit this file directly; it is auto generated.
# Instead, please edit 01-bayes_klassifikation.md in _episodes_rmd/
title: "Bayes klassifikation"
teaching: 42
exercises: 47
questions: 
- "Hvad er Bayes i relation til klassifikation"
objectives:
- "Forstå det her nok til at vi kan hjælpe studerende"

keypoints:
- "FIXME"
source: Rmd
math: yes
---



### Hvad er det?

Klassifikation baseret på Bayes teorem. 

Bayes teorem fortæller os hvordan vi opdaterer vores overbevisning om 
noget - baseret på ny viden. Det kan du læse mere om andetsteds på disse sider.



### Hvordan klassificerer vi så med Bayes?

Naiv bayes antager at de prediktive variable er uafhængige af hinanden.

Der er mange implementeringer af Naiv Bayes. En af dem finder vi i pakken e1071.

Lad os kigge på pingviner. 


~~~
library(palmerpenguins)
library(tidymodels)
~~~
{: .language-r}



~~~
── Attaching packages ────────────────────────────────────── tidymodels 1.1.0 ──
~~~
{: .output}



~~~
✔ broom        1.0.4     ✔ recipes      1.0.6
✔ dials        1.2.0     ✔ rsample      1.1.1
✔ dplyr        1.1.2     ✔ tibble       3.2.1
✔ ggplot2      3.4.2     ✔ tidyr        1.3.0
✔ infer        1.0.4     ✔ tune         1.1.1
✔ modeldata    1.1.0     ✔ workflows    1.1.3
✔ parsnip      1.1.0     ✔ workflowsets 1.0.1
✔ purrr        1.0.1     ✔ yardstick    1.2.0
~~~
{: .output}



~~~
── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──
✖ purrr::discard() masks scales::discard()
✖ dplyr::filter()  masks stats::filter()
✖ dplyr::lag()     masks stats::lag()
✖ recipes::step()  masks stats::step()
• Use tidymodels_prefer() to resolve common conflicts.
~~~
{: .output}



~~~
library(caret)
~~~
{: .language-r}



~~~
Loading required package: lattice
~~~
{: .output}



~~~

Attaching package: 'caret'
~~~
{: .output}



~~~
The following objects are masked from 'package:yardstick':

    precision, recall, sensitivity, specificity
~~~
{: .output}



~~~
The following object is masked from 'package:purrr':

    lift
~~~
{: .output}



~~~
library(e1071)
~~~
{: .language-r}



~~~

Attaching package: 'e1071'
~~~
{: .output}



~~~
The following object is masked from 'package:tune':

    tune
~~~
{: .output}



~~~
The following object is masked from 'package:rsample':

    permutations
~~~
{: .output}



~~~
The following object is masked from 'package:parsnip':

    tune
~~~
{: .output}



~~~
head(penguins)
~~~
{: .language-r}



~~~
# A tibble: 6 × 7
  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g
  <fct>   <fct>              <dbl>         <dbl>             <int>       <int>
1 Adelie  Torgersen           39.1          18.7               181        3750
2 Adelie  Torgersen           39.5          17.4               186        3800
3 Adelie  Torgersen           40.3          18                 195        3250
4 Adelie  Torgersen           NA            NA                  NA          NA
5 Adelie  Torgersen           36.7          19.3               193        3450
6 Adelie  Torgersen           39.3          20.6               190        3650
# ℹ 1 more variable: sex <fct>
~~~
{: .output}
Vi har nogen data på pingviner. Nu vil vi godt lave en model, der, baseret
på dimensioner af næb, vægt, køn og vægt, forudsiger hvilken slags pingvin
der er tale om.

Vi starter med at lave et test og et træningssæt af data. Vi piller øen 
pingvinerne er observeret på ud af datasættet:


~~~
penguin_sample <- sample(c(TRUE, FALSE), nrow(penguins), replace=TRUE, prob=c(0.8,0.2))
data <- penguins %>% select(-island)
penguin_train  <- data[penguin_sample, ]
penguin_test   <- data[!penguin_sample, ]
~~~
{: .language-r}

Så laver vi en simpel model:


~~~
penguin_model <- naiveBayes(species~., penguin_train)
~~~
{: .language-r}

Og bruger den til at forudsige hvilken slags pingviner det er vi har i vores
test-datasæt:


~~~
penguin_predictions <- predict(penguin_model, newdata = penguin_test)
~~~
{: .language-r}

Hvordan gik det?


~~~
confusionMatrix(penguin_predictions, penguin_test$species)
~~~
{: .language-r}



~~~
Confusion Matrix and Statistics

           Reference
Prediction  Adelie Chinstrap Gentoo
  Adelie        31         0      0
  Chinstrap      2        14      0
  Gentoo         0         0     24

Overall Statistics
                                          
               Accuracy : 0.9718          
                 95% CI : (0.9019, 0.9966)
    No Information Rate : 0.4648          
    P-Value [Acc > NIR] : < 2.2e-16       
                                          
                  Kappa : 0.9559          
                                          
 Mcnemar's Test P-Value : NA              

Statistics by Class:

                     Class: Adelie Class: Chinstrap Class: Gentoo
Sensitivity                 0.9394           1.0000         1.000
Specificity                 1.0000           0.9649         1.000
Pos Pred Value              1.0000           0.8750         1.000
Neg Pred Value              0.9500           1.0000         1.000
Prevalence                  0.4648           0.1972         0.338
Detection Rate              0.4366           0.1972         0.338
Detection Prevalence        0.4366           0.2254         0.338
Balanced Accuracy           0.9697           0.9825         1.000
~~~
{: .output}
Det gik fint. Der er lidt forvirring i modellen - Et par chinstrap pingviner
bliver forudsagt til at være Adelie. En enkelt Adelie pingvin bliver
forudsagt til at være en Chinstrap. 

De statistikker vi får ud når vi laver vores confusionmatrix er omtalt her
på siden om maskinlæringsmetrikker.

Hvordan ser modellen egentlig ud?

~~~
penguin_model
~~~
{: .language-r}



~~~

Naive Bayes Classifier for Discrete Predictors

Call:
naiveBayes.default(x = X, y = Y, laplace = laplace)

A-priori probabilities:
Y
   Adelie Chinstrap    Gentoo 
0.4358974 0.1978022 0.3663004 

Conditional probabilities:
           bill_length_mm
Y               [,1]     [,2]
  Adelie    38.64370 2.541074
  Chinstrap 48.80185 3.517262
  Gentoo    47.51515 3.115379

           bill_depth_mm
Y               [,1]      [,2]
  Adelie    18.33529 1.1899002
  Chinstrap 18.45185 1.1659866
  Gentoo    14.97071 0.9759613

           flipper_length_mm
Y               [,1]     [,2]
  Adelie    189.8992 6.652889
  Chinstrap 195.8333 7.434621
  Gentoo    217.1010 6.410283

           body_mass_g
Y               [,1]     [,2]
  Adelie    3684.244 461.4695
  Chinstrap 3727.315 401.3030
  Gentoo    5083.333 489.2336

           sex
Y              female      male
  Adelie    0.5043478 0.4956522
  Chinstrap 0.5185185 0.4814815
  Gentoo    0.4895833 0.5104167
~~~
{: .output}
Det bliver en del mere komplekst når der er flere parametre involveret.

Men vores priors, de sandsynligheder vi starter med, og som vi opdaterer,
er at der er 44% sandsynlighed for at det er en Adelie pingvin. Det er den andel 
af dem der er i vores træningssæt. Kigger vi på kønnene, får vi at vide at 
hvis du er en æselpingvin (gentoo), så er sandsynligheden for at du er en
hanpingvin, 0.5102041. Så når nu vi observerer at det er en hanpingvin vi har, 
så kan vi opdatere vores estimat af hvor sandsynligt det er at du er en æselpingvin.

Det er mere kompliceret for vægten dimensionerne for næb og for vingerne. Det vi
får er gennemsnit og standardafvigelse på en - antaget - normalfordeling. 
Er pingvinen en chinstrap, har den en sandsynlighedsfordeling for dens vægt. 
Hvis vi kender pingvinens vægt, kan vi udtale os om hvor sandsynlig den vægt er for
de tre forskellige slags pingviner. Og så kan vi opdatere vores estimat på hvilken
slags pingvin vi har foran os.

I praksis kigger vi nok bare på pingvinen, og ser hvilken slags pingvin den ligner.



### Hvornår bruger man Naiv Bayes i stedet for andre klassifikationer?

Lærebøgerne fortæller at Bayes har en fordel ved at håndtere både kontinuert og 
diskret data i et hug. Men er bedst til kategoriske data.  At den skalerer ret 
godt til større datasæt. Og klarer sig ret godt med mindre træningsdata end andre metoder. 

Forudsætningen er dog at de features der fittes på er uafhængige af hinanden.

Det holder ikke helt. Hanpingviner er tilbøjelige til at være større end 
hunpingviner, så køn og kropsvægt er ikke uafhængige. Længden af næbbet og dybden
af næbbet er formentlig heller ikke uafhængige. Så forudsætningerne holder nok 
ikke helt. Men det gør de sjældent.
