---
# Please do not edit this file directly; it is auto generated.
# Instead, please edit 01-bayes_klassifikation.md in _episodes_rmd/
title: "Bayes klassifikation"
teaching: 42
exercises: 47
questions: 
- "Hvad er Bayes i relation til klassifikation"
objectives:
- "Forstå det her nok til at vi kan hjælpe studerende"

keypoints:
- "FIXME"
source: Rmd
math: yes
---



### Hvad er det?

Klassifikation baseret på Bayes teorem. 

Bayes teorem fortæller os hvordan vi opdaterer vores overbevisning om 
noget - baseret på ny viden. Det kan du læse mere om andetsteds på disse sider.



### Hvordan klassificerer vi så med Bayes?

Naiv bayes antager at de prediktive variable er uafhængige af hinanden.

Der er mange implementeringer af Naiv Bayes. En af dem finder vi i pakken e1071.

Lad os kigge på pingviner. 


~~~
library(palmerpenguins)
library(tidymodels)
~~~
{: .language-r}



~~~
── Attaching packages ────────────────────────────────────── tidymodels 1.1.0 ──
~~~
{: .output}



~~~
✔ broom        1.0.5     ✔ recipes      1.0.6
✔ dials        1.2.0     ✔ rsample      1.1.1
✔ dplyr        1.1.2     ✔ tibble       3.2.1
✔ ggplot2      3.4.2     ✔ tidyr        1.3.0
✔ infer        1.0.4     ✔ tune         1.1.1
✔ modeldata    1.1.0     ✔ workflows    1.1.3
✔ parsnip      1.1.0     ✔ workflowsets 1.0.1
✔ purrr        1.0.1     ✔ yardstick    1.2.0
~~~
{: .output}



~~~
── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──
✖ purrr::discard() masks scales::discard()
✖ dplyr::filter()  masks stats::filter()
✖ dplyr::lag()     masks stats::lag()
✖ recipes::step()  masks stats::step()
• Search for functions across packages at https://www.tidymodels.org/find/
~~~
{: .output}



~~~
library(caret)
~~~
{: .language-r}



~~~
Loading required package: lattice
~~~
{: .output}



~~~

Attaching package: 'caret'
~~~
{: .output}



~~~
The following objects are masked from 'package:yardstick':

    precision, recall, sensitivity, specificity
~~~
{: .output}



~~~
The following object is masked from 'package:purrr':

    lift
~~~
{: .output}



~~~
library(e1071)
~~~
{: .language-r}



~~~

Attaching package: 'e1071'
~~~
{: .output}



~~~
The following object is masked from 'package:tune':

    tune
~~~
{: .output}



~~~
The following object is masked from 'package:rsample':

    permutations
~~~
{: .output}



~~~
The following object is masked from 'package:parsnip':

    tune
~~~
{: .output}



~~~
head(penguins)
~~~
{: .language-r}



~~~
# A tibble: 6 × 7
  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g
  <fct>   <fct>              <dbl>         <dbl>             <int>       <int>
1 Adelie  Torgersen           39.1          18.7               181        3750
2 Adelie  Torgersen           39.5          17.4               186        3800
3 Adelie  Torgersen           40.3          18                 195        3250
4 Adelie  Torgersen           NA            NA                  NA          NA
5 Adelie  Torgersen           36.7          19.3               193        3450
6 Adelie  Torgersen           39.3          20.6               190        3650
# ℹ 1 more variable: sex <fct>
~~~
{: .output}
Vi har nogen data på pingviner. Nu vil vi godt lave en model, der, baseret
på dimensioner af næb, vægt, køn og vægt, forudsiger hvilken slags pingvin
der er tale om.

Vi starter med at lave et test og et træningssæt af data. Vi piller øen 
pingvinerne er observeret på ud af datasættet:


~~~
penguin_sample <- sample(c(TRUE, FALSE), nrow(penguins), replace=TRUE, prob=c(0.8,0.2))
data <- penguins %>% select(-island)
penguin_train  <- data[penguin_sample, ]
penguin_test   <- data[!penguin_sample, ]
~~~
{: .language-r}

Så laver vi en simpel model:


~~~
penguin_model <- naiveBayes(species~., penguin_train)
~~~
{: .language-r}

Og bruger den til at forudsige hvilken slags pingviner det er vi har i vores
test-datasæt:


~~~
penguin_predictions <- predict(penguin_model, newdata = penguin_test)
~~~
{: .language-r}

Hvordan gik det?


~~~
confusionMatrix(penguin_predictions, penguin_test$species)
~~~
{: .language-r}



~~~
Confusion Matrix and Statistics

           Reference
Prediction  Adelie Chinstrap Gentoo
  Adelie        31         0      0
  Chinstrap      0         9      0
  Gentoo         0         0     23

Overall Statistics
                                     
               Accuracy : 1          
                 95% CI : (0.9431, 1)
    No Information Rate : 0.4921     
    P-Value [Acc > NIR] : < 2.2e-16  
                                     
                  Kappa : 1          
                                     
 Mcnemar's Test P-Value : NA         

Statistics by Class:

                     Class: Adelie Class: Chinstrap Class: Gentoo
Sensitivity                 1.0000           1.0000        1.0000
Specificity                 1.0000           1.0000        1.0000
Pos Pred Value              1.0000           1.0000        1.0000
Neg Pred Value              1.0000           1.0000        1.0000
Prevalence                  0.4921           0.1429        0.3651
Detection Rate              0.4921           0.1429        0.3651
Detection Prevalence        0.4921           0.1429        0.3651
Balanced Accuracy           1.0000           1.0000        1.0000
~~~
{: .output}
Det gik fint. Der er lidt forvirring i modellen - Et par chinstrap pingviner
bliver forudsagt til at være Adelie. En enkelt Adelie pingvin bliver
forudsagt til at være en Chinstrap. 

De statistikker vi får ud når vi laver vores confusionmatrix er omtalt her
på siden om maskinlæringsmetrikker.

Hvordan ser modellen egentlig ud?

~~~
penguin_model
~~~
{: .language-r}



~~~

Naive Bayes Classifier for Discrete Predictors

Call:
naiveBayes.default(x = X, y = Y, laplace = laplace)

A-priori probabilities:
Y
   Adelie Chinstrap    Gentoo 
0.4306050 0.2099644 0.3594306 

Conditional probabilities:
           bill_length_mm
Y               [,1]     [,2]
  Adelie    38.91417 2.709501
  Chinstrap 48.55932 3.442088
  Gentoo    47.54100 2.934129

           bill_depth_mm
Y               [,1]     [,2]
  Adelie    18.45417 1.247175
  Chinstrap 18.28814 1.112637
  Gentoo    14.99800 1.017422

           flipper_length_mm
Y               [,1]     [,2]
  Adelie    189.7500 6.847989
  Chinstrap 194.9831 7.025794
  Gentoo    217.3700 6.566913

           body_mass_g
Y               [,1]     [,2]
  Adelie    3716.667 454.6600
  Chinstrap 3693.220 365.9197
  Gentoo    5086.500 502.8507

           sex
Y              female      male
  Adelie    0.4655172 0.5344828
  Chinstrap 0.5593220 0.4406780
  Gentoo    0.4583333 0.5416667
~~~
{: .output}
Det bliver en del mere komplekst når der er flere parametre involveret.

Men vores priors, de sandsynligheder vi starter med, og som vi opdaterer,
er at der er 44% sandsynlighed for at det er en Adelie pingvin. Det er den andel 
af dem der er i vores træningssæt. Kigger vi på kønnene, får vi at vide at 
hvis du er en æselpingvin (gentoo), så er sandsynligheden for at du er en
hanpingvin, 0.5102041. Så når nu vi observerer at det er en hanpingvin vi har, 
så kan vi opdatere vores estimat af hvor sandsynligt det er at du er en æselpingvin.

Det er mere kompliceret for vægten dimensionerne for næb og for vingerne. Det vi
får er gennemsnit og standardafvigelse på en - antaget - normalfordeling. 
Er pingvinen en chinstrap, har den en sandsynlighedsfordeling for dens vægt. 
Hvis vi kender pingvinens vægt, kan vi udtale os om hvor sandsynlig den vægt er for
de tre forskellige slags pingviner. Og så kan vi opdatere vores estimat på hvilken
slags pingvin vi har foran os.

I praksis kigger vi nok bare på pingvinen, og ser hvilken slags pingvin den ligner.



### Hvornår bruger man Naiv Bayes i stedet for andre klassifikationer?

Lærebøgerne fortæller at Bayes har en fordel ved at håndtere både kontinuert og 
diskret data i et hug. Men er bedst til kategoriske data.  At den skalerer ret 
godt til større datasæt. Og klarer sig ret godt med mindre træningsdata end andre metoder. 

Forudsætningen er dog at de features der fittes på er uafhængige af hinanden.

Det holder ikke helt. Hanpingviner er tilbøjelige til at være større end 
hunpingviner, så køn og kropsvægt er ikke uafhængige. Længden af næbbet og dybden
af næbbet er formentlig heller ikke uafhængige. Så forudsætningerne holder nok 
ikke helt. Men det gør de sjældent.
