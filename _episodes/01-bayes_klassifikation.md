---
# Please do not edit this file directly; it is auto generated.
# Instead, please edit 01-bayes_klassifikation.md in _episodes_rmd/
title: "Bayes klassifikation"
teaching: 42
exercises: 47
questions: 
- "Hvad er Bayes i relation til klassifikation"
objectives:
- "Forstå det her nok til at vi kan hjælpe studerende"

keypoints:
- "FIXME"
source: Rmd
math: yes
---



### Hvad er det?

Klassifikation baseret på Bayes teorem. 

Bayes teorem fortæller os hvordan vi opdaterer vores overbevisning om 
noget - baseret på ny viden. Det kan du læse mere om andetsteds på disse sider.



### Hvordan klassificerer vi så med Bayes?

Naiv bayes antager at de prediktive variable er uafhængige af hinanden.

Der er mange implementeringer af Naiv Bayes. En af dem finder vi i pakken e1071.

Lad os kigge på pingviner. 


~~~
library(palmerpenguins)
library(tidymodels)
~~~
{: .language-r}



~~~
── Attaching packages ────────────────────────────────────── tidymodels 1.0.0 ──
~~~
{: .output}



~~~
✔ broom        1.0.4     ✔ recipes      1.0.5
✔ dials        1.1.0     ✔ rsample      1.1.1
✔ dplyr        1.1.1     ✔ tibble       3.2.1
✔ ggplot2      3.4.1     ✔ tidyr        1.3.0
✔ infer        1.0.4     ✔ tune         1.0.1
✔ modeldata    1.1.0     ✔ workflows    1.1.3
✔ parsnip      1.0.4     ✔ workflowsets 1.0.0
✔ purrr        1.0.1     ✔ yardstick    1.1.0
~~~
{: .output}



~~~
── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──
✖ purrr::discard() masks scales::discard()
✖ dplyr::filter()  masks stats::filter()
✖ dplyr::lag()     masks stats::lag()
✖ recipes::step()  masks stats::step()
• Use tidymodels_prefer() to resolve common conflicts.
~~~
{: .output}



~~~
library(caret)
~~~
{: .language-r}



~~~
Loading required package: lattice
~~~
{: .output}



~~~

Attaching package: 'caret'
~~~
{: .output}



~~~
The following objects are masked from 'package:yardstick':

    precision, recall, sensitivity, specificity
~~~
{: .output}



~~~
The following object is masked from 'package:purrr':

    lift
~~~
{: .output}



~~~
library(e1071)
~~~
{: .language-r}



~~~

Attaching package: 'e1071'
~~~
{: .output}



~~~
The following object is masked from 'package:tune':

    tune
~~~
{: .output}



~~~
The following object is masked from 'package:rsample':

    permutations
~~~
{: .output}



~~~
The following object is masked from 'package:parsnip':

    tune
~~~
{: .output}



~~~
head(penguins)
~~~
{: .language-r}



~~~
# A tibble: 6 × 7
  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g
  <fct>   <fct>              <dbl>         <dbl>             <int>       <int>
1 Adelie  Torgersen           39.1          18.7               181        3750
2 Adelie  Torgersen           39.5          17.4               186        3800
3 Adelie  Torgersen           40.3          18                 195        3250
4 Adelie  Torgersen           NA            NA                  NA          NA
5 Adelie  Torgersen           36.7          19.3               193        3450
6 Adelie  Torgersen           39.3          20.6               190        3650
# ℹ 1 more variable: sex <fct>
~~~
{: .output}
Vi har nogen data på pingviner. Nu vil vi godt lave en model, der, baseret
på dimensioner af næb, vægt, køn og vægt, forudsiger hvilken slags pingvin
der er tale om.

Vi starter med at lave et test og et træningssæt af data. Vi piller øen 
pingvinerne er observeret på ud af datasættet:


~~~
penguin_sample <- sample(c(TRUE, FALSE), nrow(penguins), replace=TRUE, prob=c(0.8,0.2))
data <- penguins %>% select(-island)
penguin_train  <- data[penguin_sample, ]
penguin_test   <- data[!penguin_sample, ]
~~~
{: .language-r}

Så laver vi en simpel model:


~~~
penguin_model <- naiveBayes(species~., penguin_train)
~~~
{: .language-r}

Og bruger den til at forudsige hvilken slags pingviner det er vi har i vores
test-datasæt:


~~~
penguin_predictions <- predict(penguin_model, newdata = penguin_test)
~~~
{: .language-r}

Hvordan gik det?


~~~
confusionMatrix(penguin_predictions, penguin_test$species)
~~~
{: .language-r}



~~~
Confusion Matrix and Statistics

           Reference
Prediction  Adelie Chinstrap Gentoo
  Adelie        37         1      1
  Chinstrap      0        13      0
  Gentoo         0         0     18

Overall Statistics
                                          
               Accuracy : 0.9714          
                 95% CI : (0.9006, 0.9965)
    No Information Rate : 0.5286          
    P-Value [Acc > NIR] : < 2.2e-16       
                                          
                  Kappa : 0.9523          
                                          
 Mcnemar's Test P-Value : NA              

Statistics by Class:

                     Class: Adelie Class: Chinstrap Class: Gentoo
Sensitivity                 1.0000           0.9286        0.9474
Specificity                 0.9394           1.0000        1.0000
Pos Pred Value              0.9487           1.0000        1.0000
Neg Pred Value              1.0000           0.9825        0.9808
Prevalence                  0.5286           0.2000        0.2714
Detection Rate              0.5286           0.1857        0.2571
Detection Prevalence        0.5571           0.1857        0.2571
Balanced Accuracy           0.9697           0.9643        0.9737
~~~
{: .output}
Det gik fint. Der er lidt forvirring i modellen - Et par chinstrap pingviner
bliver forudsagt til at være Adelie. En enkelt Adelie pingvin bliver
forudsagt til at være en Chinstrap. 

De statistikker vi får ud når vi laver vores confusionmatrix er omtalt her
på siden om maskinlæringsmetrikker.

Hvordan ser modellen egentlig ud?

~~~
penguin_model
~~~
{: .language-r}



~~~

Naive Bayes Classifier for Discrete Predictors

Call:
naiveBayes.default(x = X, y = Y, laplace = laplace)

A-priori probabilities:
Y
   Adelie Chinstrap    Gentoo 
0.4197080 0.1970803 0.3832117 

Conditional probabilities:
           bill_length_mm
Y               [,1]     [,2]
  Adelie    39.01316 2.713275
  Chinstrap 48.75000 3.124447
  Gentoo    47.53238 2.933313

           bill_depth_mm
Y               [,1]      [,2]
  Adelie    18.30439 1.2428479
  Chinstrap 18.50370 1.1145628
  Gentoo    15.00667 0.9717418

           flipper_length_mm
Y               [,1]     [,2]
  Adelie    189.9561 6.682947
  Chinstrap 196.0926 7.206571
  Gentoo    217.1333 6.370102

           body_mass_g
Y               [,1]     [,2]
  Adelie    3706.140 479.1396
  Chinstrap 3731.944 411.5496
  Gentoo    5071.190 498.0947

           sex
Y              female      male
  Adelie    0.5000000 0.5000000
  Chinstrap 0.4814815 0.5185185
  Gentoo    0.4752475 0.5247525
~~~
{: .output}
Det bliver en del mere komplekst når der er flere parametre involveret.

Men vores priors, de sandsynligheder vi starter med, og som vi opdaterer,
er at der er 44% sandsynlighed for at det er en Adelie pingvin. Det er den andel 
af dem der er i vores træningssæt. Kigger vi på kønnene, får vi at vide at 
hvis du er en æselpingvin (gentoo), så er sandsynligheden for at du er en
hanpingvin, 0.5102041. Så når nu vi observerer at det er en hanpingvin vi har, 
så kan vi opdatere vores estimat af hvor sandsynligt det er at du er en æselpingvin.

Det er mere kompliceret for vægten dimensionerne for næb og for vingerne. Det vi
får er gennemsnit og standardafvigelse på en - antaget - normalfordeling. 
Er pingvinen en chinstrap, har den en sandsynlighedsfordeling for dens vægt. 
Hvis vi kender pingvinens vægt, kan vi udtale os om hvor sandsynlig den vægt er for
de tre forskellige slags pingviner. Og så kan vi opdatere vores estimat på hvilken
slags pingvin vi har foran os.

I praksis kigger vi nok bare på pingvinen, og ser hvilken slags pingvin den ligner.



### Hvornår bruger man Naiv Bayes i stedet for andre klassifikationer?

Lærebøgerne fortæller at Bayes har en fordel ved at håndtere både kontinuert og 
diskret data i et hug. Men er bedst til kategoriske data.  At den skalerer ret 
godt til større datasæt. Og klarer sig ret godt med mindre træningsdata end andre metoder. 

Forudsætningen er dog at de features der fittes på er uafhængige af hinanden.

Det holder ikke helt. Hanpingviner er tilbøjelige til at være større end 
hunpingviner, så køn og kropsvægt er ikke uafhængige. Længden af næbbet og dybden
af næbbet er formentlig heller ikke uafhængige. Så forudsætningerne holder nok 
ikke helt. Men det gør de sjældent.
